{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3de6c8ba-9f26-4dbd-91dd-f95f54575ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59bf4435-7f20-4fbc-80dd-10bd479dd2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_results(label, best_numbers):\n",
    "    #Formats weekly submission form \n",
    "    print(label)\n",
    "    print(np.array2string(np.array(best_numbers), precision=6, separator='-', floatmode='fixed', formatter={'float': '{:0.6f}'.format}))\n",
    "    \n",
    "def load_and_process_data(function_num=1, num_weeks=1):\n",
    "    # Load initial data\n",
    "    def load_data(i):\n",
    "        X = np.load(f'initial_data/function_{i}/initial_inputs.npy')\n",
    "        y = np.load(f'initial_data/function_{i}/initial_outputs.npy')\n",
    "        return X, y\n",
    "\n",
    "    def load_data_2(i):\n",
    "        X = np.load(f'initial_data2/function_{i}/initial_inputs.npy')\n",
    "        y = np.load(f'initial_data2/function_{i}/initial_outputs.npy')\n",
    "        return X, y\n",
    "        \n",
    "    X, y = load_data(function_num)\n",
    "    dimension = X.shape[1]\n",
    "    print(f\"Shape of initial X: {X.shape}\")\n",
    "    print(f\"Shape of initial y: {y.shape}\")\n",
    "\n",
    "    # Load and combine weekly data\n",
    "    for week in range(1, num_weeks + 1):\n",
    "        results_dir = f'results/week{week}'\n",
    "        X_week = np.load(f'{results_dir}/f{function_num}.npy')\n",
    "        y_week = np.load(f'{results_dir}/f_y{function_num}.npy')\n",
    "        \n",
    "        # Combine data\n",
    "        X = np.vstack((X, X_week))\n",
    "        y = np.concatenate((y, y_week))\n",
    "        \n",
    "        print(f\"After week {week}:\")\n",
    "        print(f\"Shape of X: {X.shape}\")\n",
    "        print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "    print(f\"\\nadded new data Batch week20\")\n",
    "    X2, y2 = load_data(function_num)\n",
    "    #dimension = X2.shape[1]\n",
    "    print(f\"Shape of initial X2: {X2.shape}\")\n",
    "    print(f\"Shape of initial y2: {y2.shape}\")\n",
    "    X = np.vstack((X, X2))\n",
    "    y = np.concatenate((y, y2))\n",
    "\n",
    "    # Create DataFrame\n",
    "    column_names = [f'X{i+1}' for i in range(X.shape[1])]\n",
    "    df = pd.DataFrame(X, columns=column_names)\n",
    "    df['y'] = y\n",
    "    \n",
    "    # Find maximum y value and corresponding row\n",
    "    max_y = df['y'].max()\n",
    "    max_row = df.loc[df['y'] == max_y]\n",
    "\n",
    "   \n",
    "    \n",
    "    print(f\"\\nFinal DataFrame shape: {df.shape}\")\n",
    "    print(df)\n",
    "    print(f\"\\nThe maximum y is: {max_y}\")\n",
    "    print(\"\\nThe row with the max y is:\")\n",
    "    print(max_row)\n",
    "    \n",
    "    return X, y, df, max_y, max_row.iloc[0]\n",
    "\n",
    "# Example usage\n",
    "#function_num = 1\n",
    "#num_weeks = 2  # Process data for 3 weeks\n",
    "#X, y, df, max_y, max_row = load_and_process_data(function_num, num_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c49fc508-47fa-4a97-ae27-19f7577f3b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of initial X: (10, 2)\n",
      "Shape of initial y: (10,)\n",
      "After week 1:\n",
      "Shape of X: (11, 2)\n",
      "Shape of y: (11,)\n",
      "After week 2:\n",
      "Shape of X: (12, 2)\n",
      "Shape of y: (12,)\n",
      "After week 3:\n",
      "Shape of X: (13, 2)\n",
      "Shape of y: (13,)\n",
      "After week 4:\n",
      "Shape of X: (14, 2)\n",
      "Shape of y: (14,)\n",
      "After week 5:\n",
      "Shape of X: (15, 2)\n",
      "Shape of y: (15,)\n",
      "After week 6:\n",
      "Shape of X: (16, 2)\n",
      "Shape of y: (16,)\n",
      "After week 7:\n",
      "Shape of X: (17, 2)\n",
      "Shape of y: (17,)\n",
      "After week 8:\n",
      "Shape of X: (18, 2)\n",
      "Shape of y: (18,)\n",
      "After week 9:\n",
      "Shape of X: (19, 2)\n",
      "Shape of y: (19,)\n",
      "\n",
      "added new data Batch week20\n",
      "Shape of initial X2: (10, 2)\n",
      "Shape of initial y2: (10,)\n",
      "\n",
      "Final DataFrame shape: (29, 3)\n",
      "          X1        X2              y\n",
      "0   0.319404  0.762959   1.322677e-79\n",
      "1   0.574329  0.879898   1.033078e-46\n",
      "2   0.731024  0.733000   7.710875e-16\n",
      "3   0.840353  0.264732  3.341771e-124\n",
      "4   0.650114  0.681526  -3.606063e-03\n",
      "5   0.410437  0.147554  -2.159249e-54\n",
      "6   0.312691  0.078723  -2.089093e-91\n",
      "7   0.683418  0.861057   2.535001e-40\n",
      "8   0.082507  0.403488   3.606771e-81\n",
      "9   0.883890  0.582254   6.229856e-48\n",
      "10  0.670114  0.701526   2.247051e-06\n",
      "11  0.668342  0.703518   4.145435e-07\n",
      "12  0.668342  0.778894  -6.367055e-19\n",
      "13  0.748744  0.648241   6.607457e-12\n",
      "14  0.748744  0.969849   9.181610e-93\n",
      "15  0.422111  0.984925  1.259310e-119\n",
      "16  0.979899  0.417085 -1.315233e-118\n",
      "17  0.620114  0.651526   4.385952e-01\n",
      "18  0.637461  0.701526  -3.199600e-04\n",
      "19  0.319404  0.762959   1.322677e-79\n",
      "20  0.574329  0.879898   1.033078e-46\n",
      "21  0.731024  0.733000   7.710875e-16\n",
      "22  0.840353  0.264732  3.341771e-124\n",
      "23  0.650114  0.681526  -3.606063e-03\n",
      "24  0.410437  0.147554  -2.159249e-54\n",
      "25  0.312691  0.078723  -2.089093e-91\n",
      "26  0.683418  0.861057   2.535001e-40\n",
      "27  0.082507  0.403488   3.606771e-81\n",
      "28  0.883890  0.582254   6.229856e-48\n",
      "\n",
      "The maximum y is: 0.43859515912233876\n",
      "\n",
      "The row with the max y is:\n",
      "          X1        X2         y\n",
      "17  0.620114  0.651526  0.438595\n"
     ]
    }
   ],
   "source": [
    "function_num = 1\n",
    "num_week = 9\n",
    "\n",
    "X, y, df, max_y, max_row = load_and_process_data(function_num, num_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b3df31-3975-463c-8125-f641aaf9669d",
   "metadata": {},
   "source": [
    "##  BayesianOptimizer class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "853be1f2-70b8-4362-9d16-927b6bf2386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import norm\n",
    "device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "class GPModel(ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(GPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = ScaleKernel(RBFKernel(ard_num_dims=train_x.shape[1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "class BayesianOptimizer:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.y_scaled = torch.tensor(self.scaler.fit_transform(y.reshape(-1, 1)).flatten(), dtype=torch.float32)\n",
    "        self.likelihood = GaussianLikelihood()\n",
    "        self.model = GPModel(self.X, self.y_scaled, self.likelihood)\n",
    "        \n",
    "    def train(self, training_iter=400, lr=0.1):\n",
    "        self.model.train()\n",
    "        self.likelihood.train()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        mll = ExactMarginalLogLikelihood(self.likelihood, self.model)\n",
    "        \n",
    "        for i in range(training_iter):\n",
    "            optimizer.zero_grad()\n",
    "            output = self.model(self.X)\n",
    "            loss = -mll(output, self.y_scaled)\n",
    "            loss.backward()\n",
    "            if i % 20 == 19:\n",
    "                print(f'Iter {i + 1}/{training_iter} - Loss: {loss.item():.4f}   Noise: {self.model.likelihood.noise.item():.4f}')\n",
    "            optimizer.step()\n",
    "        \n",
    "        self.model.eval()\n",
    "        self.likelihood.eval()\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_grid(X, num_points=100, hypercube_size=None, X_ini=None):\n",
    "        num_vars = X.shape[1]\n",
    "        \n",
    "        if hypercube_size is not None:\n",
    "            if X_ini is None:\n",
    "                center = X.mean(axis=0)\n",
    "            else:\n",
    "                center = X_ini\n",
    "            \n",
    "            ranges = []\n",
    "            for i in range(num_vars):\n",
    "                lower_bound = max(0, center[i] - hypercube_size/2)\n",
    "                upper_bound = min(1, center[i] + hypercube_size/2)\n",
    "                ranges.append(np.linspace(lower_bound, upper_bound, num_points))\n",
    "        else:\n",
    "            ranges = [np.linspace(X[:, i].min(), X[:, i].max(), num_points) for i in range(num_vars)]\n",
    "        \n",
    "        grid = np.array(np.meshgrid(*ranges)).T.reshape(-1, num_vars)\n",
    "        return grid\n",
    "    \n",
    "    @staticmethod\n",
    "    def expected_improvement(mean, sigma, best_f, xi=0.01):\n",
    "        with torch.no_grad():\n",
    "            z = (mean - best_f - xi) / sigma\n",
    "            normal = torch.distributions.Normal(torch.zeros_like(z), torch.ones_like(z))\n",
    "            ei = (mean - best_f - xi) * normal.cdf(z) + sigma * normal.log_prob(z).exp()\n",
    "        return ei\n",
    "    \n",
    "    def optimize(self, num_points=50, hypercube_size=0.5, X_ini=None):\n",
    "        if X_ini is None:\n",
    "            X_ini = self.X[self.y_scaled.argmax()]\n",
    "        \n",
    "        grid = self.create_grid(self.X.numpy(), num_points, hypercube_size, X_ini.numpy())\n",
    "        grid_tensor = torch.tensor(grid, dtype=torch.float32)\n",
    "        \n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            predictions = self.likelihood(self.model(grid_tensor))\n",
    "            mean = predictions.mean\n",
    "            sigma = predictions.stddev\n",
    "        \n",
    "        best_f = self.y_scaled.max().item()\n",
    "        ei = self.expected_improvement(mean, sigma, best_f)\n",
    "        \n",
    "        max_ei_value, max_ei_index = ei.max(0)\n",
    "        max_ei_input = grid[max_ei_index]\n",
    "        max_ei_prediction = mean[max_ei_index].item()\n",
    "        max_ei_prediction_original = self.scaler.inverse_transform([[max_ei_prediction]])[0][0]\n",
    "        \n",
    "        actual_max_value = self.y_scaled.max().item()\n",
    "        actual_max_value_original = self.scaler.inverse_transform([[actual_max_value]])[0][0]\n",
    "        actual_max_index = self.y_scaled.argmax().item()\n",
    "        actual_max_input = self.X[actual_max_index].numpy()\n",
    "        \n",
    "        results = {\n",
    "            \"max_ei_input\": max_ei_input,\n",
    "            \"max_ei_prediction\": max_ei_prediction_original,\n",
    "            \"max_ei_value\": max_ei_value.item(),\n",
    "            \"actual_max_input\": actual_max_input,\n",
    "            \"actual_max_value\": actual_max_value_original\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Example usage:\n",
    "# optimizer = BayesianOptimizer(X, y)\n",
    "# optimizer.train()\n",
    "# results = optimizer.optimize()\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29c44b06-b5d2-4a91-b31d-7e9c2abf4e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claud\\AppData\\Local\\Temp\\ipykernel_32040\\2251220785.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20/500 - Loss: 0.1183   Noise: 0.1372\n",
      "Iter 40/500 - Loss: -0.2234   Noise: 0.0285\n",
      "Iter 60/500 - Loss: -0.2600   Noise: 0.0345\n",
      "Iter 80/500 - Loss: -0.2751   Noise: 0.0339\n",
      "Iter 100/500 - Loss: -0.2826   Noise: 0.0331\n",
      "Iter 120/500 - Loss: -0.2857   Noise: 0.0331\n",
      "Iter 140/500 - Loss: -0.2870   Noise: 0.0330\n",
      "Iter 160/500 - Loss: -0.2877   Noise: 0.0329\n",
      "Iter 180/500 - Loss: -0.2876   Noise: 0.0330\n",
      "Iter 200/500 - Loss: -0.2884   Noise: 0.0329\n",
      "Iter 220/500 - Loss: -0.2887   Noise: 0.0329\n",
      "Iter 240/500 - Loss: -0.2888   Noise: 0.0329\n",
      "Iter 260/500 - Loss: -0.2878   Noise: 0.0329\n",
      "Iter 280/500 - Loss: -0.2891   Noise: 0.0328\n",
      "Iter 300/500 - Loss: -0.2891   Noise: 0.0328\n",
      "Iter 320/500 - Loss: -0.2892   Noise: 0.0328\n",
      "Iter 340/500 - Loss: -0.2892   Noise: 0.0328\n",
      "Iter 360/500 - Loss: -0.2890   Noise: 0.0329\n",
      "Iter 380/500 - Loss: -0.2893   Noise: 0.0328\n",
      "Iter 400/500 - Loss: -0.2894   Noise: 0.0328\n",
      "Iter 420/500 - Loss: -0.2894   Noise: 0.0328\n",
      "Iter 440/500 - Loss: -0.2883   Noise: 0.0329\n",
      "Iter 460/500 - Loss: -0.2893   Noise: 0.0328\n",
      "Iter 480/500 - Loss: -0.2895   Noise: 0.0328\n",
      "Iter 500/500 - Loss: -0.2895   Noise: 0.0328\n",
      "Optimization Results:\n",
      "Best point found: [0.62317525 0.70152597]\n",
      "Predicted value at best point (scaled): 0.0413384772837162\n",
      "Predicted value at best point (original scale): 0.014673862516470893\n",
      "Expected Improvement: -1.2743647914703615e-08\n",
      "\n",
      "Actual best point in training data: [0.620114 0.651526]\n",
      "Actual best value in training data (scaled): 1.0\n",
      "Actual best value in training data (original scale): 0.4385951591223387\n",
      "\n",
      "Function Number: 1\n",
      "Next query:\n",
      "[0.623175-0.701526]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from bayesian_optimizer import BayesianOptimizer\n",
    "\n",
    "# Scale y values\n",
    "scaler = MinMaxScaler()\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Convert numpy arrays to torch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y_scaled = torch.tensor(y_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create and use the optimizer\n",
    "optimizer = BayesianOptimizer(X, y_scaled)\n",
    "optimizer.train(training_iter=500)\n",
    "results = optimizer.optimize(num_points=50, hypercube_size=0.1)\n",
    "\n",
    "print(\"Optimization Results:\")\n",
    "print(f\"Best point found: {results['max_ei_input']}\")\n",
    "print(f\"Predicted value at best point (scaled): {results['max_ei_prediction']}\")\n",
    "print(f\"Predicted value at best point (original scale): {scaler.inverse_transform([[results['max_ei_prediction']]])[0][0]}\")\n",
    "print(f\"Expected Improvement: {results['max_ei_value']}\")\n",
    "print(f\"\\nActual best point in training data: {results['actual_max_input']}\")\n",
    "print(f\"Actual best value in training data (scaled): {results['actual_max_value']}\")\n",
    "print(f\"Actual best value in training data (original scale): {scaler.inverse_transform([[results['actual_max_value']]])[0][0]}\")\n",
    "print('\\nFunction Number:',function_num)\n",
    "format_results('Next query:', results['max_ei_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adfd566a-2e29-4c50-b764-aa155112f6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of initial X: (10, 2)\n",
      "Shape of initial y: (10,)\n",
      "After week 1:\n",
      "Shape of X: (11, 2)\n",
      "Shape of y: (11,)\n",
      "After week 2:\n",
      "Shape of X: (12, 2)\n",
      "Shape of y: (12,)\n",
      "After week 3:\n",
      "Shape of X: (13, 2)\n",
      "Shape of y: (13,)\n",
      "After week 4:\n",
      "Shape of X: (14, 2)\n",
      "Shape of y: (14,)\n",
      "After week 5:\n",
      "Shape of X: (15, 2)\n",
      "Shape of y: (15,)\n",
      "After week 6:\n",
      "Shape of X: (16, 2)\n",
      "Shape of y: (16,)\n",
      "After week 7:\n",
      "Shape of X: (17, 2)\n",
      "Shape of y: (17,)\n",
      "After week 8:\n",
      "Shape of X: (18, 2)\n",
      "Shape of y: (18,)\n",
      "After week 9:\n",
      "Shape of X: (19, 2)\n",
      "Shape of y: (19,)\n",
      "\n",
      "added new data Batch week20\n",
      "Shape of initial X2: (10, 2)\n",
      "Shape of initial y2: (10,)\n",
      "\n",
      "Final DataFrame shape: (29, 3)\n",
      "          X1        X2         y\n",
      "0   0.665800  0.123969  0.538996\n",
      "1   0.877791  0.778628  0.420586\n",
      "2   0.142699  0.349005 -0.065624\n",
      "3   0.845275  0.711120  0.293993\n",
      "4   0.454647  0.290455  0.214965\n",
      "5   0.577713  0.771973  0.023106\n",
      "6   0.438166  0.685018  0.244619\n",
      "7   0.341750  0.028698  0.038749\n",
      "8   0.338648  0.213867 -0.013858\n",
      "9   0.702637  0.926564  0.611205\n",
      "10  0.775510  0.959184  0.023768\n",
      "11  0.714286  0.938776  0.451086\n",
      "12  0.693878  0.897959  0.563238\n",
      "13  0.693878  0.918367  0.521920\n",
      "14  0.714286  0.918367  0.490105\n",
      "15  0.693878  0.938776  0.636626\n",
      "16  0.693878  0.877551  0.583641\n",
      "17  0.684694  0.988776  0.593574\n",
      "18  0.686735  0.999999  0.529268\n",
      "19  0.665800  0.123969  0.538996\n",
      "20  0.877791  0.778628  0.420586\n",
      "21  0.142699  0.349005 -0.065624\n",
      "22  0.845275  0.711120  0.293993\n",
      "23  0.454647  0.290455  0.214965\n",
      "24  0.577713  0.771973  0.023106\n",
      "25  0.438166  0.685018  0.244619\n",
      "26  0.341750  0.028698  0.038749\n",
      "27  0.338648  0.213867 -0.013858\n",
      "28  0.702637  0.926564  0.611205\n",
      "\n",
      "The maximum y is: 0.636626128478489\n",
      "\n",
      "The row with the max y is:\n",
      "          X1        X2         y\n",
      "15  0.693878  0.938776  0.636626\n"
     ]
    }
   ],
   "source": [
    "function_num = 2\n",
    "num_week = 9\n",
    "\n",
    "X, y, df, max_y, max_row = load_and_process_data(function_num, num_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f30821e1-5dc3-4a77-9b58-bd6091dc66f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claud\\AppData\\Local\\Temp\\ipykernel_32040\\2251220785.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20/200 - Loss: 0.2779   Noise: 0.1403\n",
      "Iter 40/200 - Loss: -0.2708   Noise: 0.0328\n",
      "Iter 60/200 - Loss: -0.7913   Noise: 0.0052\n",
      "Iter 80/200 - Loss: -0.9004   Noise: 0.0017\n",
      "Iter 100/200 - Loss: -0.9132   Noise: 0.0021\n",
      "Iter 120/200 - Loss: -0.9139   Noise: 0.0022\n",
      "Iter 140/200 - Loss: -0.9145   Noise: 0.0021\n",
      "Iter 160/200 - Loss: -0.9148   Noise: 0.0022\n",
      "Iter 180/200 - Loss: -0.9151   Noise: 0.0022\n",
      "Iter 200/200 - Loss: -0.9153   Noise: 0.0022\n",
      "Optimization Results:\n",
      "Best point found: [0.68622493 0.86377602]\n",
      "Predicted value at best point (scaled): 0.9274374842643738\n",
      "Predicted value at best point (original scale): 0.5856691197321947\n",
      "Expected Improvement: 0.001004224643111229\n",
      "\n",
      "Actual best point in training data: [0.693878 0.938776]\n",
      "Actual best value in training data (scaled): 1.0\n",
      "Actual best value in training data (original scale): 0.636626128478489\n",
      "\n",
      "Function Number: 2\n",
      "Next query:\n",
      "[0.686225-0.863776]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scale y values\n",
    "scaler = MinMaxScaler()\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y_scaled = torch.tensor(y_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create and use the optimizer\n",
    "optimizer = BayesianOptimizer(X, y_scaled)\n",
    "optimizer.train(training_iter=200)\n",
    "results = optimizer.optimize(num_points=50, hypercube_size=0.15)\n",
    "\n",
    "print(\"Optimization Results:\")\n",
    "print(f\"Best point found: {results['max_ei_input']}\")\n",
    "print(f\"Predicted value at best point (scaled): {results['max_ei_prediction']}\")\n",
    "print(f\"Predicted value at best point (original scale): {scaler.inverse_transform([[results['max_ei_prediction']]])[0][0]}\")\n",
    "print(f\"Expected Improvement: {results['max_ei_value']}\")\n",
    "print(f\"\\nActual best point in training data: {results['actual_max_input']}\")\n",
    "print(f\"Actual best value in training data (scaled): {results['actual_max_value']}\")\n",
    "print(f\"Actual best value in training data (original scale): {scaler.inverse_transform([[results['actual_max_value']]])[0][0]}\")\n",
    "print('\\nFunction Number:',function_num)\n",
    "format_results('Next query:', results['max_ei_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "994de6f8-bcd0-43ab-98ac-e6ee5c43d2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of initial X: (15, 3)\n",
      "Shape of initial y: (15,)\n",
      "After week 1:\n",
      "Shape of X: (16, 3)\n",
      "Shape of y: (16,)\n",
      "After week 2:\n",
      "Shape of X: (17, 3)\n",
      "Shape of y: (17,)\n",
      "After week 3:\n",
      "Shape of X: (18, 3)\n",
      "Shape of y: (18,)\n",
      "After week 4:\n",
      "Shape of X: (19, 3)\n",
      "Shape of y: (19,)\n",
      "After week 5:\n",
      "Shape of X: (20, 3)\n",
      "Shape of y: (20,)\n",
      "After week 6:\n",
      "Shape of X: (21, 3)\n",
      "Shape of y: (21,)\n",
      "After week 7:\n",
      "Shape of X: (22, 3)\n",
      "Shape of y: (22,)\n",
      "After week 8:\n",
      "Shape of X: (23, 3)\n",
      "Shape of y: (23,)\n",
      "After week 9:\n",
      "Shape of X: (24, 3)\n",
      "Shape of y: (24,)\n",
      "\n",
      "added new data Batch week20\n",
      "Shape of initial X2: (15, 3)\n",
      "Shape of initial y2: (15,)\n",
      "\n",
      "Final DataFrame shape: (39, 4)\n",
      "          X1        X2        X3         y\n",
      "0   0.171525  0.343917  0.248737 -0.112122\n",
      "1   0.242114  0.644074  0.272433 -0.087963\n",
      "2   0.534906  0.398501  0.173389 -0.111415\n",
      "3   0.492581  0.611593  0.340176 -0.034835\n",
      "4   0.134622  0.219917  0.458206 -0.048008\n",
      "5   0.345523  0.941360  0.269363 -0.110621\n",
      "6   0.151837  0.439991  0.990882 -0.398926\n",
      "7   0.645503  0.397143  0.919771 -0.113869\n",
      "8   0.746912  0.284196  0.226300 -0.131461\n",
      "9   0.170477  0.697032  0.149169 -0.094190\n",
      "10  0.220549  0.297825  0.343555 -0.046947\n",
      "11  0.666014  0.671985  0.246295 -0.105965\n",
      "12  0.046809  0.231360  0.770618 -0.118048\n",
      "13  0.600097  0.725136  0.066089 -0.036378\n",
      "14  0.965995  0.861120  0.566829 -0.056758\n",
      "15  0.469388  0.102041  0.530612 -0.063759\n",
      "16  0.571429  0.755102  0.000000 -0.111727\n",
      "17  0.612245  0.714286  0.102041 -0.059114\n",
      "18  0.714286  0.612245  0.000000 -0.111977\n",
      "19  0.326531  0.306122  0.408163 -0.031368\n",
      "20  0.489796  0.999990  0.999999 -0.479587\n",
      "21  0.755102  0.612245  0.448980 -0.001021\n",
      "22  0.855102  0.712245  0.438776 -0.021626\n",
      "23  0.855102  0.593878  0.504082 -0.004866\n",
      "24  0.171525  0.343917  0.248737 -0.112122\n",
      "25  0.242114  0.644074  0.272433 -0.087963\n",
      "26  0.534906  0.398501  0.173389 -0.111415\n",
      "27  0.492581  0.611593  0.340176 -0.034835\n",
      "28  0.134622  0.219917  0.458206 -0.048008\n",
      "29  0.345523  0.941360  0.269363 -0.110621\n",
      "30  0.151837  0.439991  0.990882 -0.398926\n",
      "31  0.645503  0.397143  0.919771 -0.113869\n",
      "32  0.746912  0.284196  0.226300 -0.131461\n",
      "33  0.170477  0.697032  0.149169 -0.094190\n",
      "34  0.220549  0.297825  0.343555 -0.046947\n",
      "35  0.666014  0.671985  0.246295 -0.105965\n",
      "36  0.046809  0.231360  0.770618 -0.118048\n",
      "37  0.600097  0.725136  0.066089 -0.036378\n",
      "38  0.965995  0.861120  0.566829 -0.056758\n",
      "\n",
      "The maximum y is: -0.0010214738225351222\n",
      "\n",
      "The row with the max y is:\n",
      "          X1        X2       X3         y\n",
      "21  0.755102  0.612245  0.44898 -0.001021\n"
     ]
    }
   ],
   "source": [
    "function_num = 3\n",
    "num_week = 9\n",
    "\n",
    "X, y, df, max_y, max_row = load_and_process_data(function_num, num_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74a060dd-2ba2-43e9-80f2-c72649a3547a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claud\\AppData\\Local\\Temp\\ipykernel_32040\\2251220785.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20/200 - Loss: 0.1234   Noise: 0.1371\n",
      "Iter 40/200 - Loss: -0.4672   Noise: 0.0238\n",
      "Iter 60/200 - Loss: -1.0309   Noise: 0.0045\n",
      "Iter 80/200 - Loss: -1.4984   Noise: 0.0008\n",
      "Iter 100/200 - Loss: -1.6552   Noise: 0.0003\n",
      "Iter 120/200 - Loss: -1.6770   Noise: 0.0002\n",
      "Iter 140/200 - Loss: -1.7783   Noise: 0.0002\n",
      "Iter 160/200 - Loss: -1.8284   Noise: 0.0001\n",
      "Iter 180/200 - Loss: -1.8524   Noise: 0.0001\n",
      "Iter 200/200 - Loss: -1.8651   Noise: 0.0001\n",
      "Optimization Results:\n",
      "Best point found: [0.85510198 0.56938788 0.49183715]\n",
      "Predicted value at best point (scaled): 0.9929190278053284\n",
      "Predicted value at best point (original scale): -0.004410183142779513\n",
      "Expected Improvement: 0.0008205580525100231\n",
      "\n",
      "Actual best point in training data: [0.755102 0.612245 0.44898 ]\n",
      "Actual best value in training data (scaled): 1.0\n",
      "Actual best value in training data (original scale): -0.001021473822535214\n",
      "\n",
      "Function Number: 3\n",
      "Next query:\n",
      "[0.855102-0.569388-0.491837]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scale y values\n",
    "scaler = MinMaxScaler()\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y_scaled = torch.tensor(y_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create and use the optimizer\n",
    "optimizer = BayesianOptimizer(X, y_scaled)\n",
    "optimizer.train(training_iter=200)\n",
    "results = optimizer.optimize(num_points=50, hypercube_size=0.2)\n",
    "\n",
    "print(\"Optimization Results:\")\n",
    "print(f\"Best point found: {results['max_ei_input']}\")\n",
    "print(f\"Predicted value at best point (scaled): {results['max_ei_prediction']}\")\n",
    "print(f\"Predicted value at best point (original scale): {scaler.inverse_transform([[results['max_ei_prediction']]])[0][0]}\")\n",
    "print(f\"Expected Improvement: {results['max_ei_value']}\")\n",
    "print(f\"\\nActual best point in training data: {results['actual_max_input']}\")\n",
    "print(f\"Actual best value in training data (scaled): {results['actual_max_value']}\")\n",
    "print(f\"Actual best value in training data (original scale): {scaler.inverse_transform([[results['actual_max_value']]])[0][0]}\")\n",
    "print('\\nFunction Number:',function_num)\n",
    "format_results('Next query:', results['max_ei_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54c0e6a5-f00a-4321-a1fc-2c8db85c3dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of initial X: (30, 4)\n",
      "Shape of initial y: (30,)\n",
      "After week 1:\n",
      "Shape of X: (31, 4)\n",
      "Shape of y: (31,)\n",
      "After week 2:\n",
      "Shape of X: (32, 4)\n",
      "Shape of y: (32,)\n",
      "After week 3:\n",
      "Shape of X: (33, 4)\n",
      "Shape of y: (33,)\n",
      "After week 4:\n",
      "Shape of X: (34, 4)\n",
      "Shape of y: (34,)\n",
      "After week 5:\n",
      "Shape of X: (35, 4)\n",
      "Shape of y: (35,)\n",
      "After week 6:\n",
      "Shape of X: (36, 4)\n",
      "Shape of y: (36,)\n",
      "After week 7:\n",
      "Shape of X: (37, 4)\n",
      "Shape of y: (37,)\n",
      "After week 8:\n",
      "Shape of X: (38, 4)\n",
      "Shape of y: (38,)\n",
      "After week 9:\n",
      "Shape of X: (39, 4)\n",
      "Shape of y: (39,)\n",
      "\n",
      "added new data Batch week20\n",
      "Shape of initial X2: (30, 4)\n",
      "Shape of initial y2: (30,)\n",
      "\n",
      "Final DataFrame shape: (69, 5)\n",
      "          X1        X2        X3        X4          y\n",
      "0   0.896981  0.725628  0.175404  0.701694 -22.108288\n",
      "1   0.889356  0.499588  0.539269  0.508783 -14.601397\n",
      "2   0.250946  0.033693  0.145380  0.494932 -11.699932\n",
      "3   0.346962  0.006250  0.760564  0.613024 -16.053765\n",
      "4   0.124871  0.129770  0.384400  0.287076 -10.069633\n",
      "..       ...       ...       ...       ...        ...\n",
      "64  0.948389  0.894513  0.851638  0.552196 -32.625660\n",
      "65  0.664955  0.046566  0.116777  0.793718 -19.989498\n",
      "66  0.577766  0.428772  0.425826  0.249007  -4.025542\n",
      "67  0.738613  0.482103  0.709366  0.503970 -13.122782\n",
      "68  0.854811  0.493965  0.735310  0.808092 -23.139428\n",
      "\n",
      "[69 rows x 5 columns]\n",
      "\n",
      "The maximum y is: 0.5591489570434409\n",
      "\n",
      "The row with the max y is:\n",
      "          X1        X2        X3        X4         y\n",
      "34  0.418571  0.397755  0.377347  0.418163  0.559149\n"
     ]
    }
   ],
   "source": [
    "function_num = 4\n",
    "num_week = 9\n",
    "\n",
    "X, y, df, max_y, max_row = load_and_process_data(function_num, num_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16d33b93-2883-4d50-853f-b509aead579b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20/400 - Loss: 0.1329   Noise: 0.1372\n",
      "Iter 40/400 - Loss: -0.6412   Noise: 0.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claud\\AppData\\Local\\Temp\\ipykernel_17416\\2251220785.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 60/400 - Loss: -1.3535   Noise: 0.0029\n",
      "Iter 80/400 - Loss: -1.8515   Noise: 0.0006\n",
      "Iter 100/400 - Loss: -2.1023   Noise: 0.0002\n",
      "Iter 120/400 - Loss: -2.1878   Noise: 0.0001\n",
      "Iter 140/400 - Loss: -2.2177   Noise: 0.0001\n",
      "Iter 160/400 - Loss: -2.2313   Noise: 0.0001\n",
      "Iter 180/400 - Loss: -2.2390   Noise: 0.0001\n",
      "Iter 200/400 - Loss: -2.2440   Noise: 0.0001\n",
      "Iter 220/400 - Loss: -2.2475   Noise: 0.0001\n",
      "Iter 240/400 - Loss: -2.2500   Noise: 0.0001\n",
      "Iter 260/400 - Loss: -2.2520   Noise: 0.0001\n",
      "Iter 280/400 - Loss: -2.2535   Noise: 0.0001\n",
      "Iter 300/400 - Loss: -2.2548   Noise: 0.0001\n",
      "Iter 320/400 - Loss: -2.2558   Noise: 0.0001\n",
      "Iter 340/400 - Loss: -2.2566   Noise: 0.0001\n",
      "Iter 360/400 - Loss: -2.2574   Noise: 0.0001\n",
      "Iter 380/400 - Loss: -2.2580   Noise: 0.0001\n",
      "Iter 400/400 - Loss: -2.2585   Noise: 0.0001\n",
      "Optimization Results:\n",
      "Best point found: [0.42163222 0.40081622 0.33142863 0.42734668]\n",
      "Predicted value at best point (scaled): 0.9880874156951904\n",
      "Predicted value at best point (original scale): 0.16383212013099124\n",
      "Expected Improvement: 8.92267853487283e-05\n",
      "\n",
      "Actual best point in training data: [0.418571 0.397755 0.377347 0.418163]\n",
      "Actual best value in training data (scaled): 1.0\n",
      "Actual best value in training data (original scale): 0.5591489570434419\n",
      "\n",
      "Function Number: 4\n",
      "Next query:\n",
      "[0.421632-0.400816-0.331429-0.427347]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scale y values\n",
    "scaler = MinMaxScaler()\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y_scaled = torch.tensor(y_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create and use the optimizer\n",
    "optimizer = BayesianOptimizer(X, y_scaled)\n",
    "optimizer.train(training_iter=400)\n",
    "results = optimizer.optimize(num_points=50, hypercube_size=0.3)\n",
    "\n",
    "print(\"Optimization Results:\")\n",
    "print(f\"Best point found: {results['max_ei_input']}\")\n",
    "print(f\"Predicted value at best point (scaled): {results['max_ei_prediction']}\")\n",
    "print(f\"Predicted value at best point (original scale): {scaler.inverse_transform([[results['max_ei_prediction']]])[0][0]}\")\n",
    "print(f\"Expected Improvement: {results['max_ei_value']}\")\n",
    "print(f\"\\nActual best point in training data: {results['actual_max_input']}\")\n",
    "print(f\"Actual best value in training data (scaled): {results['actual_max_value']}\")\n",
    "print(f\"Actual best value in training data (original scale): {scaler.inverse_transform([[results['actual_max_value']]])[0][0]}\")\n",
    "print('\\nFunction Number:',function_num)\n",
    "format_results('Next query:', results['max_ei_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b57487f-96cd-4e82-b39b-02cb3ff298a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of initial X: (20, 4)\n",
      "Shape of initial y: (20,)\n",
      "After week 1:\n",
      "Shape of X: (21, 4)\n",
      "Shape of y: (21,)\n",
      "After week 2:\n",
      "Shape of X: (22, 4)\n",
      "Shape of y: (22,)\n",
      "After week 3:\n",
      "Shape of X: (23, 4)\n",
      "Shape of y: (23,)\n",
      "After week 4:\n",
      "Shape of X: (24, 4)\n",
      "Shape of y: (24,)\n",
      "After week 5:\n",
      "Shape of X: (25, 4)\n",
      "Shape of y: (25,)\n",
      "After week 6:\n",
      "Shape of X: (26, 4)\n",
      "Shape of y: (26,)\n",
      "After week 7:\n",
      "Shape of X: (27, 4)\n",
      "Shape of y: (27,)\n",
      "After week 8:\n",
      "Shape of X: (28, 4)\n",
      "Shape of y: (28,)\n",
      "After week 9:\n",
      "Shape of X: (29, 4)\n",
      "Shape of y: (29,)\n",
      "\n",
      "added new data Batch week20\n",
      "Shape of initial X2: (20, 4)\n",
      "Shape of initial y2: (20,)\n",
      "\n",
      "Final DataFrame shape: (49, 5)\n",
      "          X1        X2        X3        X4            y\n",
      "0   0.191447  0.038193  0.607418  0.414584    64.443440\n",
      "1   0.758653  0.536518  0.656000  0.360342    18.301380\n",
      "2   0.438350  0.804340  0.210245  0.151295     0.112940\n",
      "3   0.706051  0.534192  0.264243  0.482088     4.210898\n",
      "4   0.836478  0.193610  0.663893  0.785649   258.370525\n",
      "5   0.683432  0.118663  0.829046  0.567577    78.434389\n",
      "6   0.553621  0.667350  0.323806  0.814870    57.571537\n",
      "7   0.352356  0.322242  0.116979  0.473113   109.571876\n",
      "8   0.153786  0.729382  0.422598  0.443074     8.847992\n",
      "9   0.463442  0.630025  0.107906  0.957644   233.223610\n",
      "10  0.677491  0.358510  0.479592  0.072880    24.423088\n",
      "11  0.583973  0.147243  0.348097  0.428615    64.420147\n",
      "12  0.306889  0.316878  0.622634  0.095399    63.476716\n",
      "13  0.511142  0.817957  0.728710  0.112354    79.729130\n",
      "14  0.438933  0.774092  0.378167  0.933696   355.806818\n",
      "15  0.224189  0.846480  0.879484  0.878516  1088.859618\n",
      "16  0.725262  0.479870  0.088947  0.759760    28.866752\n",
      "17  0.355482  0.639619  0.417618  0.122604    45.181570\n",
      "18  0.119879  0.862540  0.643331  0.849804   431.612757\n",
      "19  0.126885  0.153430  0.770162  0.190518     9.972332\n",
      "20  0.224490  0.836735  0.877551  0.877551  1035.787416\n",
      "21  0.224490  0.836735  0.877551  0.877551  1035.787416\n",
      "22  0.224490  0.857143  0.897959  0.877551  1223.352760\n",
      "23  0.224490  0.857143  0.918367  0.877551  1337.576725\n",
      "24  0.224490  0.857143  0.938776  0.897959  1581.754867\n",
      "25  0.224490  0.857143  0.959184  0.918367  1865.088705\n",
      "26  0.224490  0.857143  0.959184  0.918367  1865.088705\n",
      "27  0.199490  0.882143  0.984184  0.943367  2437.767773\n",
      "28  0.177054  0.904579  0.999999  0.968367  3015.421935\n",
      "29  0.191447  0.038193  0.607418  0.414584    64.443440\n",
      "30  0.758653  0.536518  0.656000  0.360342    18.301380\n",
      "31  0.438350  0.804340  0.210245  0.151295     0.112940\n",
      "32  0.706051  0.534192  0.264243  0.482088     4.210898\n",
      "33  0.836478  0.193610  0.663893  0.785649   258.370525\n",
      "34  0.683432  0.118663  0.829046  0.567577    78.434389\n",
      "35  0.553621  0.667350  0.323806  0.814870    57.571537\n",
      "36  0.352356  0.322242  0.116979  0.473113   109.571876\n",
      "37  0.153786  0.729382  0.422598  0.443074     8.847992\n",
      "38  0.463442  0.630025  0.107906  0.957644   233.223610\n",
      "39  0.677491  0.358510  0.479592  0.072880    24.423088\n",
      "40  0.583973  0.147243  0.348097  0.428615    64.420147\n",
      "41  0.306889  0.316878  0.622634  0.095399    63.476716\n",
      "42  0.511142  0.817957  0.728710  0.112354    79.729130\n",
      "43  0.438933  0.774092  0.378167  0.933696   355.806818\n",
      "44  0.224189  0.846480  0.879484  0.878516  1088.859618\n",
      "45  0.725262  0.479870  0.088947  0.759760    28.866752\n",
      "46  0.355482  0.639619  0.417618  0.122604    45.181570\n",
      "47  0.119879  0.862540  0.643331  0.849804   431.612757\n",
      "48  0.126885  0.153430  0.770162  0.190518     9.972332\n",
      "\n",
      "The maximum y is: 3015.421934877656\n",
      "\n",
      "The row with the max y is:\n",
      "          X1        X2        X3        X4            y\n",
      "28  0.177054  0.904579  0.999999  0.968367  3015.421935\n"
     ]
    }
   ],
   "source": [
    "function_num = 5\n",
    "num_week = 9\n",
    "\n",
    "X, y, df, max_y, max_row = load_and_process_data(function_num, num_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16f47cd0-30d1-4314-a07e-ea8dc524b24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20/500 - Loss: 0.0873   Noise: 0.1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claud\\AppData\\Local\\Temp\\ipykernel_17416\\2251220785.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 40/500 - Loss: -0.6359   Noise: 0.0200\n",
      "Iter 60/500 - Loss: -1.2213   Noise: 0.0033\n",
      "Iter 80/500 - Loss: -1.4692   Noise: 0.0010\n",
      "Iter 100/500 - Loss: -1.5587   Noise: 0.0005\n",
      "Iter 120/500 - Loss: -1.7082   Noise: 0.0003\n",
      "Iter 140/500 - Loss: -1.7916   Noise: 0.0002\n",
      "Iter 160/500 - Loss: -1.8541   Noise: 0.0001\n",
      "Iter 180/500 - Loss: -1.9179   Noise: 0.0001\n",
      "Iter 200/500 - Loss: -1.9340   Noise: 0.0001\n",
      "Iter 220/500 - Loss: -1.9424   Noise: 0.0001\n",
      "Iter 240/500 - Loss: -1.9480   Noise: 0.0001\n",
      "Iter 260/500 - Loss: -1.9529   Noise: 0.0001\n",
      "Iter 280/500 - Loss: -1.9592   Noise: 0.0001\n",
      "Iter 300/500 - Loss: -1.9676   Noise: 0.0001\n",
      "Iter 320/500 - Loss: -1.9695   Noise: 0.0001\n",
      "Iter 340/500 - Loss: -1.9707   Noise: 0.0001\n",
      "Iter 360/500 - Loss: -1.9717   Noise: 0.0001\n",
      "Iter 380/500 - Loss: -1.9724   Noise: 0.0001\n",
      "Iter 400/500 - Loss: -1.9730   Noise: 0.0001\n",
      "Iter 420/500 - Loss: -1.9735   Noise: 0.0001\n",
      "Iter 440/500 - Loss: -1.9743   Noise: 0.0001\n",
      "Iter 460/500 - Loss: -1.9745   Noise: 0.0001\n",
      "Iter 480/500 - Loss: -1.9748   Noise: 0.0001\n",
      "Iter 500/500 - Loss: -1.9752   Noise: 0.0001\n",
      "Optimization Results:\n",
      "Best point found: [0.152054   0.92957898 1.         0.99336698]\n",
      "Predicted value at best point (scaled): 0.9923152923583984\n",
      "Predicted value at best point (original scale): 2992.250166801357\n",
      "Expected Improvement: 0.0008871399331837893\n",
      "\n",
      "Actual best point in training data: [0.177054 0.904579 0.999999 0.968367]\n",
      "Actual best value in training data (scaled): 1.0\n",
      "Actual best value in training data (original scale): 3015.421934877656\n",
      "\n",
      "Function Number: 5\n",
      "Next query:\n",
      "[0.152054-0.929579-1.000000-0.993367]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scale y values\n",
    "scaler = MinMaxScaler()\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y_scaled = torch.tensor(y_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create and use the optimizer\n",
    "optimizer = BayesianOptimizer(X, y_scaled)\n",
    "optimizer.train(training_iter=500)\n",
    "results = optimizer.optimize(num_points=40, hypercube_size=0.05)\n",
    "\n",
    "print(\"Optimization Results:\")\n",
    "print(f\"Best point found: {results['max_ei_input']}\")\n",
    "print(f\"Predicted value at best point (scaled): {results['max_ei_prediction']}\")\n",
    "print(f\"Predicted value at best point (original scale): {scaler.inverse_transform([[results['max_ei_prediction']]])[0][0]}\")\n",
    "print(f\"Expected Improvement: {results['max_ei_value']}\")\n",
    "print(f\"\\nActual best point in training data: {results['actual_max_input']}\")\n",
    "print(f\"Actual best value in training data (scaled): {results['actual_max_value']}\")\n",
    "print(f\"Actual best value in training data (original scale): {scaler.inverse_transform([[results['actual_max_value']]])[0][0]}\")\n",
    "print('\\nFunction Number:',function_num)\n",
    "format_results('Next query:', results['max_ei_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c10e080-7168-4b8a-9f44-de6bba8c8aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of initial X: (20, 5)\n",
      "Shape of initial y: (20,)\n",
      "After week 1:\n",
      "Shape of X: (21, 5)\n",
      "Shape of y: (21,)\n",
      "After week 2:\n",
      "Shape of X: (22, 5)\n",
      "Shape of y: (22,)\n",
      "After week 3:\n",
      "Shape of X: (23, 5)\n",
      "Shape of y: (23,)\n",
      "After week 4:\n",
      "Shape of X: (24, 5)\n",
      "Shape of y: (24,)\n",
      "After week 5:\n",
      "Shape of X: (25, 5)\n",
      "Shape of y: (25,)\n",
      "After week 6:\n",
      "Shape of X: (26, 5)\n",
      "Shape of y: (26,)\n",
      "After week 7:\n",
      "Shape of X: (27, 5)\n",
      "Shape of y: (27,)\n",
      "After week 8:\n",
      "Shape of X: (28, 5)\n",
      "Shape of y: (28,)\n",
      "After week 9:\n",
      "Shape of X: (29, 5)\n",
      "Shape of y: (29,)\n",
      "\n",
      "added new data Batch week20\n",
      "Shape of initial X2: (20, 5)\n",
      "Shape of initial y2: (20,)\n",
      "\n",
      "Final DataFrame shape: (49, 6)\n",
      "          X1        X2        X3        X4        X5         y\n",
      "0   0.728186  0.154693  0.732552  0.693997  0.056401 -0.714265\n",
      "1   0.242384  0.844100  0.577809  0.679021  0.501953 -1.209955\n",
      "2   0.729523  0.748106  0.679775  0.356552  0.671054 -1.672200\n",
      "3   0.770620  0.114404  0.046780  0.648324  0.273549 -1.536058\n",
      "4   0.618812  0.331802  0.187288  0.756238  0.328835 -0.829237\n",
      "5   0.784958  0.910682  0.708120  0.959225  0.004911 -1.247049\n",
      "6   0.145111  0.896685  0.896322  0.726272  0.236272 -1.233786\n",
      "7   0.945069  0.288459  0.978806  0.961656  0.598016 -1.694343\n",
      "8   0.125720  0.862725  0.028544  0.246605  0.751206 -2.571170\n",
      "9   0.757594  0.355831  0.016523  0.434207  0.112433 -1.309116\n",
      "10  0.536797  0.308781  0.411879  0.388225  0.522528 -1.144785\n",
      "11  0.957740  0.235669  0.099146  0.156806  0.071317 -1.912677\n",
      "12  0.629308  0.803484  0.811408  0.045613  0.110624 -1.622839\n",
      "13  0.021735  0.428084  0.835939  0.489489  0.511082 -1.356682\n",
      "14  0.439344  0.698924  0.426820  0.109476  0.877888 -2.018425\n",
      "15  0.258906  0.793678  0.642114  0.196673  0.593103 -1.702558\n",
      "16  0.432166  0.715618  0.341819  0.705000  0.614962 -1.294247\n",
      "17  0.782880  0.536336  0.443284  0.859700  0.010326 -0.935757\n",
      "18  0.921776  0.931871  0.414876  0.595057  0.735626 -2.155768\n",
      "19  0.126679  0.291470  0.064528  0.680515  0.892819 -1.746882\n",
      "20  0.473684  0.421053  0.315789  0.842105  0.263158 -0.754840\n",
      "21  0.684211  0.052632  0.842105  0.631579  0.000000 -1.084899\n",
      "22  0.628186  0.054693  0.632552  0.593997  0.156401 -0.808452\n",
      "23  0.678186  0.204693  0.782552  0.743997  0.006401 -0.603483\n",
      "24  0.678186  0.254693  0.732552  0.793997  0.026600 -0.500936\n",
      "25  0.631579  0.263158  0.684211  0.842105  0.052632 -0.497229\n",
      "26  0.581579  0.363158  0.684211  0.742105  0.114474 -0.220968\n",
      "27  0.536751  0.401089  0.611797  0.649002  0.090336 -0.391611\n",
      "28  0.598820  0.401089  0.784211  0.724864  0.214474 -0.596241\n",
      "29  0.728186  0.154693  0.732552  0.693997  0.056401 -0.714265\n",
      "30  0.242384  0.844100  0.577809  0.679021  0.501953 -1.209955\n",
      "31  0.729523  0.748106  0.679775  0.356552  0.671054 -1.672200\n",
      "32  0.770620  0.114404  0.046780  0.648324  0.273549 -1.536058\n",
      "33  0.618812  0.331802  0.187288  0.756238  0.328835 -0.829237\n",
      "34  0.784958  0.910682  0.708120  0.959225  0.004911 -1.247049\n",
      "35  0.145111  0.896685  0.896322  0.726272  0.236272 -1.233786\n",
      "36  0.945069  0.288459  0.978806  0.961656  0.598016 -1.694343\n",
      "37  0.125720  0.862725  0.028544  0.246605  0.751206 -2.571170\n",
      "38  0.757594  0.355831  0.016523  0.434207  0.112433 -1.309116\n",
      "39  0.536797  0.308781  0.411879  0.388225  0.522528 -1.144785\n",
      "40  0.957740  0.235669  0.099146  0.156806  0.071317 -1.912677\n",
      "41  0.629308  0.803484  0.811408  0.045613  0.110624 -1.622839\n",
      "42  0.021735  0.428084  0.835939  0.489489  0.511082 -1.356682\n",
      "43  0.439344  0.698924  0.426820  0.109476  0.877888 -2.018425\n",
      "44  0.258906  0.793678  0.642114  0.196673  0.593103 -1.702558\n",
      "45  0.432166  0.715618  0.341819  0.705000  0.614962 -1.294247\n",
      "46  0.782880  0.536336  0.443284  0.859700  0.010326 -0.935757\n",
      "47  0.921776  0.931871  0.414876  0.595057  0.735626 -2.155768\n",
      "48  0.126679  0.291470  0.064528  0.680515  0.892819 -1.746882\n",
      "\n",
      "The maximum y is: -0.22096796504637056\n",
      "\n",
      "The row with the max y is:\n",
      "          X1        X2        X3        X4        X5         y\n",
      "26  0.581579  0.363158  0.684211  0.742105  0.114474 -0.220968\n"
     ]
    }
   ],
   "source": [
    "function_num = 6\n",
    "num_week = 9\n",
    "\n",
    "X, y, df, max_y, max_row = load_and_process_data(function_num, num_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7bdf639e-1992-4a90-ad06-43fd97a6c927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20/500 - Loss: 0.1046   Noise: 0.1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claud\\AppData\\Local\\Temp\\ipykernel_17416\\2251220785.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 40/500 - Loss: -0.4963   Noise: 0.0210\n",
      "Iter 60/500 - Loss: -1.0432   Noise: 0.0045\n",
      "Iter 80/500 - Loss: -1.2872   Noise: 0.0012\n",
      "Iter 100/500 - Loss: -1.4398   Noise: 0.0006\n",
      "Iter 120/500 - Loss: -1.5742   Noise: 0.0003\n",
      "Iter 140/500 - Loss: -1.6730   Noise: 0.0002\n",
      "Iter 160/500 - Loss: -1.7183   Noise: 0.0001\n",
      "Iter 180/500 - Loss: -1.7388   Noise: 0.0001\n",
      "Iter 200/500 - Loss: -1.7543   Noise: 0.0001\n",
      "Iter 220/500 - Loss: -1.7742   Noise: 0.0001\n",
      "Iter 240/500 - Loss: -1.7829   Noise: 0.0001\n",
      "Iter 260/500 - Loss: -1.7869   Noise: 0.0001\n",
      "Iter 280/500 - Loss: -1.7895   Noise: 0.0001\n",
      "Iter 300/500 - Loss: -1.7913   Noise: 0.0001\n",
      "Iter 320/500 - Loss: -1.7927   Noise: 0.0001\n",
      "Iter 340/500 - Loss: -1.7939   Noise: 0.0001\n",
      "Iter 360/500 - Loss: -1.7948   Noise: 0.0001\n",
      "Iter 380/500 - Loss: -1.7956   Noise: 0.0001\n",
      "Iter 400/500 - Loss: -1.7962   Noise: 0.0001\n",
      "Iter 420/500 - Loss: -1.7968   Noise: 0.0001\n",
      "Iter 440/500 - Loss: -1.7972   Noise: 0.0001\n",
      "Iter 460/500 - Loss: -1.7976   Noise: 0.0001\n",
      "Iter 480/500 - Loss: -1.7980   Noise: 0.0001\n",
      "Iter 500/500 - Loss: -1.7983   Noise: 0.0001\n",
      "Optimization Results:\n",
      "Best point found: [0.53675144 0.38039937 0.58421102 0.74555328 0.08343952]\n",
      "Predicted value at best point (scaled): 1.051208257675171\n",
      "Predicted value at best point (original scale): -0.10061823251646033\n",
      "Expected Improvement: 0.041712015867233276\n",
      "\n",
      "Actual best point in training data: [0.581579 0.363158 0.684211 0.742105 0.114474]\n",
      "Actual best value in training data (scaled): 1.0\n",
      "Actual best value in training data (original scale): -0.22096796504637065\n",
      "\n",
      "Function Number: 6\n",
      "Next query:\n",
      "[0.536751-0.380399-0.584211-0.745553-0.083440]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scale y values\n",
    "scaler = MinMaxScaler()\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y_scaled = torch.tensor(y_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create and use the optimizer\n",
    "optimizer = BayesianOptimizer(X, y_scaled)\n",
    "optimizer.train(training_iter=500)\n",
    "results = optimizer.optimize(num_points=30, hypercube_size=0.2)\n",
    "\n",
    "print(\"Optimization Results:\")\n",
    "print(f\"Best point found: {results['max_ei_input']}\")\n",
    "print(f\"Predicted value at best point (scaled): {results['max_ei_prediction']}\")\n",
    "print(f\"Predicted value at best point (original scale): {scaler.inverse_transform([[results['max_ei_prediction']]])[0][0]}\")\n",
    "print(f\"Expected Improvement: {results['max_ei_value']}\")\n",
    "print(f\"\\nActual best point in training data: {results['actual_max_input']}\")\n",
    "print(f\"Actual best value in training data (scaled): {results['actual_max_value']}\")\n",
    "print(f\"Actual best value in training data (original scale): {scaler.inverse_transform([[results['actual_max_value']]])[0][0]}\")\n",
    "print('\\nFunction Number:',function_num)\n",
    "format_results('Next query:', results['max_ei_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0776cb2f-c6d8-4b90-8892-4825879a82d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of initial X: (30, 6)\n",
      "Shape of initial y: (30,)\n",
      "After week 1:\n",
      "Shape of X: (31, 6)\n",
      "Shape of y: (31,)\n",
      "After week 2:\n",
      "Shape of X: (32, 6)\n",
      "Shape of y: (32,)\n",
      "After week 3:\n",
      "Shape of X: (33, 6)\n",
      "Shape of y: (33,)\n",
      "After week 4:\n",
      "Shape of X: (34, 6)\n",
      "Shape of y: (34,)\n",
      "After week 5:\n",
      "Shape of X: (35, 6)\n",
      "Shape of y: (35,)\n",
      "After week 6:\n",
      "Shape of X: (36, 6)\n",
      "Shape of y: (36,)\n",
      "After week 7:\n",
      "Shape of X: (37, 6)\n",
      "Shape of y: (37,)\n",
      "After week 8:\n",
      "Shape of X: (38, 6)\n",
      "Shape of y: (38,)\n",
      "After week 9:\n",
      "Shape of X: (39, 6)\n",
      "Shape of y: (39,)\n",
      "\n",
      "added new data Batch week20\n",
      "Shape of initial X2: (30, 6)\n",
      "Shape of initial y2: (30,)\n",
      "\n",
      "Final DataFrame shape: (69, 7)\n",
      "          X1        X2        X3        X4        X5        X6         y\n",
      "0   0.272624  0.324495  0.897109  0.832951  0.154063  0.795864  0.604433\n",
      "1   0.543003  0.924694  0.341567  0.646486  0.718440  0.343133  0.562753\n",
      "2   0.090832  0.661529  0.065931  0.258577  0.963453  0.640265  0.007503\n",
      "3   0.118867  0.615055  0.905816  0.855300  0.413631  0.585236  0.061424\n",
      "4   0.630218  0.838097  0.680013  0.731895  0.526737  0.348429  0.273047\n",
      "..       ...       ...       ...       ...       ...       ...       ...\n",
      "64  0.066611  0.528045  0.816095  0.961017  0.086509  0.777788  0.516457\n",
      "65  0.932466  0.488812  0.258608  0.956243  0.190428  0.519852  0.003777\n",
      "66  0.846867  0.142429  0.060669  0.756292  0.552398  0.081306  0.003134\n",
      "67  0.806282  0.324122  0.726076  0.148712  0.719376  0.362884  0.021343\n",
      "68  0.476823  0.340942  0.014335  0.880140  0.998655  0.079664  0.095411\n",
      "\n",
      "[69 rows x 7 columns]\n",
      "\n",
      "The maximum y is: 2.2970015668039387\n",
      "\n",
      "The row with the max y is:\n",
      "          X1        X2        X3       X4        X5        X6         y\n",
      "37  0.222222  0.233333  0.433333  0.08254  0.290476  0.652381  2.297002\n"
     ]
    }
   ],
   "source": [
    "function_num = 7\n",
    "num_week = 9\n",
    "\n",
    "X, y, df, max_y, max_row = load_and_process_data(function_num, num_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfe969b8-fe1e-45d3-9902-d529101ee189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claud\\AppData\\Local\\Temp\\ipykernel_17416\\2251220785.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20/500 - Loss: 0.1502   Noise: 0.1366\n",
      "Iter 40/500 - Loss: -0.3631   Noise: 0.0255\n",
      "Iter 60/500 - Loss: -0.9465   Noise: 0.0049\n",
      "Iter 80/500 - Loss: -1.3574   Noise: 0.0010\n",
      "Iter 100/500 - Loss: -1.6192   Noise: 0.0003\n",
      "Iter 120/500 - Loss: -1.7424   Noise: 0.0002\n",
      "Iter 140/500 - Loss: -1.7894   Noise: 0.0001\n",
      "Iter 160/500 - Loss: -1.8084   Noise: 0.0001\n",
      "Iter 180/500 - Loss: -1.8180   Noise: 0.0001\n",
      "Iter 200/500 - Loss: -1.8236   Noise: 0.0001\n",
      "Iter 220/500 - Loss: -1.8272   Noise: 0.0001\n",
      "Iter 240/500 - Loss: -1.8300   Noise: 0.0001\n",
      "Iter 260/500 - Loss: -1.8319   Noise: 0.0001\n",
      "Iter 280/500 - Loss: -1.8335   Noise: 0.0001\n",
      "Iter 300/500 - Loss: -1.8347   Noise: 0.0001\n",
      "Iter 320/500 - Loss: -1.8357   Noise: 0.0001\n",
      "Iter 340/500 - Loss: -1.8365   Noise: 0.0001\n",
      "Iter 360/500 - Loss: -1.8367   Noise: 0.0001\n",
      "Iter 380/500 - Loss: -1.8377   Noise: 0.0001\n",
      "Iter 400/500 - Loss: -1.8382   Noise: 0.0001\n",
      "Iter 420/500 - Loss: -1.8386   Noise: 0.0001\n",
      "Iter 440/500 - Loss: -1.8390   Noise: 0.0001\n",
      "Iter 460/500 - Loss: -1.8394   Noise: 0.0001\n",
      "Iter 480/500 - Loss: -1.8396   Noise: 0.0001\n",
      "Iter 500/500 - Loss: -1.8399   Noise: 0.0001\n",
      "Optimization Results:\n",
      "Best point found: [0.222222   0.13333301 0.53333301 0.11734714 0.23333314 0.652381  ]\n",
      "Predicted value at best point (scaled): 1.0182042121887207\n",
      "Predicted value at best point (original scale): 2.338767492681335\n",
      "Expected Improvement: 0.02679308131337166\n",
      "\n",
      "Actual best point in training data: [0.222222 0.233333 0.433333 0.08254  0.290476 0.652381]\n",
      "Actual best value in training data (scaled): 1.0\n",
      "Actual best value in training data (original scale): 2.2970015668039387\n",
      "\n",
      "Function Number: 7\n",
      "Next query:\n",
      "[0.222222-0.133333-0.533333-0.117347-0.233333-0.652381]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scale y values\n",
    "scaler = MinMaxScaler()\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y_scaled = torch.tensor(y_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create and use the optimizer\n",
    "optimizer = BayesianOptimizer(X, y_scaled)\n",
    "optimizer.train(training_iter=500)\n",
    "results = optimizer.optimize(num_points=15, hypercube_size=0.2)\n",
    "\n",
    "print(\"Optimization Results:\")\n",
    "print(f\"Best point found: {results['max_ei_input']}\")\n",
    "print(f\"Predicted value at best point (scaled): {results['max_ei_prediction']}\")\n",
    "print(f\"Predicted value at best point (original scale): {scaler.inverse_transform([[results['max_ei_prediction']]])[0][0]}\")\n",
    "print(f\"Expected Improvement: {results['max_ei_value']}\")\n",
    "print(f\"\\nActual best point in training data: {results['actual_max_input']}\")\n",
    "print(f\"Actual best value in training data (scaled): {results['actual_max_value']}\")\n",
    "print(f\"Actual best value in training data (original scale): {scaler.inverse_transform([[results['actual_max_value']]])[0][0]}\")\n",
    "print('\\nFunction Number:',function_num)\n",
    "format_results('Next query:', results['max_ei_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e16dd86e-796b-48f1-8775-1f40169835db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of initial X: (40, 8)\n",
      "Shape of initial y: (40,)\n",
      "After week 1:\n",
      "Shape of X: (41, 8)\n",
      "Shape of y: (41,)\n",
      "After week 2:\n",
      "Shape of X: (42, 8)\n",
      "Shape of y: (42,)\n",
      "After week 3:\n",
      "Shape of X: (43, 8)\n",
      "Shape of y: (43,)\n",
      "After week 4:\n",
      "Shape of X: (44, 8)\n",
      "Shape of y: (44,)\n",
      "After week 5:\n",
      "Shape of X: (45, 8)\n",
      "Shape of y: (45,)\n",
      "After week 6:\n",
      "Shape of X: (46, 8)\n",
      "Shape of y: (46,)\n",
      "After week 7:\n",
      "Shape of X: (47, 8)\n",
      "Shape of y: (47,)\n",
      "After week 8:\n",
      "Shape of X: (48, 8)\n",
      "Shape of y: (48,)\n",
      "After week 9:\n",
      "Shape of X: (49, 8)\n",
      "Shape of y: (49,)\n",
      "\n",
      "added new data Batch week20\n",
      "Shape of initial X2: (40, 8)\n",
      "Shape of initial y2: (40,)\n",
      "\n",
      "Final DataFrame shape: (89, 9)\n",
      "          X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0   0.604994  0.292215  0.908453  0.355506  0.201669  0.575338  0.310311   \n",
      "1   0.178007  0.566223  0.994862  0.210325  0.320153  0.707909  0.635384   \n",
      "2   0.009077  0.811626  0.520520  0.075687  0.265112  0.091652  0.592415   \n",
      "3   0.506028  0.653730  0.363411  0.177981  0.093728  0.197425  0.755827   \n",
      "4   0.359909  0.249076  0.495997  0.709215  0.114987  0.289207  0.557295   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "84  0.472071  0.168203  0.086428  0.452656  0.480619  0.622439  0.928974   \n",
      "85  0.856007  0.638894  0.326192  0.668503  0.240298  0.210299  0.167546   \n",
      "86  0.810032  0.635046  0.269548  0.869605  0.661922  0.252259  0.765670   \n",
      "87  0.796253  0.007037  0.355697  0.487566  0.740520  0.706650  0.992914   \n",
      "88  0.481245  0.102461  0.219486  0.677322  0.247509  0.244341  0.163825   \n",
      "\n",
      "          X8         y  \n",
      "0   0.734281  7.398721  \n",
      "1   0.107132  7.005227  \n",
      "2   0.367320  8.459482  \n",
      "3   0.292472  8.284008  \n",
      "4   0.593882  8.606117  \n",
      "..       ...       ...  \n",
      "84  0.112536  8.472936  \n",
      "85  0.963590  7.977685  \n",
      "86  0.890549  7.460872  \n",
      "87  0.381734  7.436594  \n",
      "88  0.715962  9.183005  \n",
      "\n",
      "[89 rows x 9 columns]\n",
      "\n",
      "The maximum y is: 9.844993710642\n",
      "\n",
      "The row with the max y is:\n",
      "     X1     X2   X3   X4        X5        X6        X7        X8         y\n",
      "48  0.1  0.075  0.1  0.0  0.303935  0.501055  0.188307  0.693085  9.844994\n"
     ]
    }
   ],
   "source": [
    "function_num = 8\n",
    "num_week = 9\n",
    "\n",
    "X, y, df, max_y, max_row = load_and_process_data(function_num, num_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49b33182-fc21-49c9-8847-7af2a271fa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 20/500 - Loss: 0.0576   Noise: 0.1343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claud\\AppData\\Local\\Temp\\ipykernel_17416\\2251220785.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 40/500 - Loss: -0.8143   Noise: 0.0176\n",
      "Iter 60/500 - Loss: -1.5258   Noise: 0.0026\n",
      "Iter 80/500 - Loss: -2.0595   Noise: 0.0005\n",
      "Iter 100/500 - Loss: -2.3659   Noise: 0.0002\n",
      "Iter 120/500 - Loss: -2.4849   Noise: 0.0001\n",
      "Iter 140/500 - Loss: -2.5292   Noise: 0.0001\n",
      "Iter 160/500 - Loss: -2.5496   Noise: 0.0001\n",
      "Iter 180/500 - Loss: -2.5614   Noise: 0.0001\n",
      "Iter 200/500 - Loss: -2.5691   Noise: 0.0001\n",
      "Iter 220/500 - Loss: -2.5744   Noise: 0.0001\n",
      "Iter 240/500 - Loss: -2.5785   Noise: 0.0001\n",
      "Iter 260/500 - Loss: -2.5816   Noise: 0.0001\n",
      "Iter 280/500 - Loss: -2.5842   Noise: 0.0001\n",
      "Iter 300/500 - Loss: -2.5864   Noise: 0.0001\n",
      "Iter 320/500 - Loss: -2.5882   Noise: 0.0001\n",
      "Iter 340/500 - Loss: -2.5895   Noise: 0.0001\n",
      "Iter 360/500 - Loss: -2.5909   Noise: 0.0001\n",
      "Iter 380/500 - Loss: -2.5921   Noise: 0.0001\n",
      "Iter 400/500 - Loss: -2.5932   Noise: 0.0001\n",
      "Iter 420/500 - Loss: -2.5941   Noise: 0.0001\n",
      "Iter 440/500 - Loss: -2.5948   Noise: 0.0001\n",
      "Iter 460/500 - Loss: -2.5957   Noise: 0.0001\n",
      "Iter 480/500 - Loss: -2.5964   Noise: 0.0001\n",
      "Iter 500/500 - Loss: -2.5970   Noise: 0.0001\n",
      "Optimization Results:\n",
      "Best point found: [0.125      0.075      0.15       0.         0.35393499 0.451055\n",
      " 0.188307   0.74308501]\n",
      "Predicted value at best point (scaled): 1.015820026397705\n",
      "Predicted value at best point (original scale): 9.912273123986\n",
      "Expected Improvement: 0.008596640080213547\n",
      "\n",
      "Actual best point in training data: [0.1      0.075    0.1      0.       0.303935 0.501055 0.188307 0.693085]\n",
      "Actual best value in training data (scaled): 1.0\n",
      "Actual best value in training data (original scale): 9.844993710642\n",
      "\n",
      "Function Number: 8\n",
      "Next query:\n",
      "[0.125000-0.075000-0.150000-0.000000-0.353935-0.451055-0.188307-0.743085]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scale y values\n",
    "scaler = MinMaxScaler()\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y_scaled = torch.tensor(y_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create and use the optimizer\n",
    "optimizer = BayesianOptimizer(X, y_scaled)\n",
    "optimizer.train(training_iter=500)\n",
    "results = optimizer.optimize(num_points=5, hypercube_size=0.1)\n",
    "\n",
    "print(\"Optimization Results:\")\n",
    "print(f\"Best point found: {results['max_ei_input']}\")\n",
    "print(f\"Predicted value at best point (scaled): {results['max_ei_prediction']}\")\n",
    "print(f\"Predicted value at best point (original scale): {scaler.inverse_transform([[results['max_ei_prediction']]])[0][0]}\")\n",
    "print(f\"Expected Improvement: {results['max_ei_value']}\")\n",
    "print(f\"\\nActual best point in training data: {results['actual_max_input']}\")\n",
    "print(f\"Actual best value in training data (scaled): {results['actual_max_value']}\")\n",
    "print(f\"Actual best value in training data (original scale): {scaler.inverse_transform([[results['actual_max_value']]])[0][0]}\")\n",
    "print('\\nFunction Number:',function_num)\n",
    "format_results('Next query:', results['max_ei_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45902758-49b9-4a19-9583-166c724ff2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
